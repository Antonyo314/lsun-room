(this.webpackJsonpprojectize=this.webpackJsonpprojectize||[]).push([[0],{160:function(e,a,t){e.exports=t(289)},289:function(e,a,t){"use strict";t.r(a);var n=t(0),r=t.n(n),i=t(37),o=t.n(i),l=t(29),c=t(68),m=t(8),s=t(151),u=t(324),g=t(325),p=t(318),h=t(292),d=t(313),f=t(327),E=t(315),b=t(316),v=t(323),y=t(319),w=t(320),k=t(321),S=t(322),I=t(311),C=t(312),x=t(141),L=t.n(x),F=t(142),j=t.n(F),N=Object(I.a)((function(e){var a;return{toolbar:{borderBottom:"1px solid ".concat(e.palette.divider),backgroundImage:"radial-gradient(circle, rgb(55, 58, 68) 0%, #3F3F3F 100%)",color:"#fff",zIndex:0},toolbarTitle:{flex:1},toolbarSecondary:(a={justifyContent:"center",backgroundColor:"#E8E5E9",zIndex:0,"& > a":{padding:e.spacing(0,5)}},Object(l.a)(a,e.breakpoints.down("md"),{"& > a":{padding:e.spacing(0,3)}}),Object(l.a)(a,e.breakpoints.down("xs"),{"& > a":{padding:e.spacing(0,1)}}),a),toolbarLink:{padding:e.spacing(1),flexShrink:0}}}));function P(e){var a=N(),t=e.sections,n=e.title,i=e.githubPage;return r.a.createElement(r.a.Fragment,null,r.a.createElement(C.a,{className:a.toolbar},r.a.createElement(h.a,{component:"h2",variant:"h5",color:"inherit",align:"center",noWrap:!0,className:a.toolbarTitle},n)),r.a.createElement(C.a,{component:"nav",variant:"dense",className:a.toolbarSecondary},t.map((function(e){return r.a.createElement(d.a,{color:"inherit",noWrap:!0,key:e.title,variant:"body2",href:"/lsun-room"+e.url,className:a.toolbarLink},e.title)}))),i?r.a.createElement(j.a,null,r.a.createElement(L.a,{href:i})):"")}var H=t(326),R=t(314),W=Object(I.a)((function(e){return{title:{padding:e.spacing(3,0),margin:e.spacing(6,0,0,0)},text:{fontFamily:"Source Serif Pro"}}}));function z(e){var a=W(),t=e.name,n=e.anchor,i=e.fontVariant;return r.a.createElement(H.a,{className:a.title,id:n},r.a.createElement(h.a,{className:a.text,align:"left",component:"h4",variant:i?i.variant:"h4",gutterBottom:!0},t),r.a.createElement(R.a,null))}var A=Object(I.a)((function(e){return{authorAffiliationItem:Object(l.a)({padding:e.spacing(0,2,0)},e.breakpoints.down("md"),{padding:e.spacing(0,.5,0)})}}));function O(e){var a=A(),t=e.authors,n=e.affiliations;return r.a.createElement(r.a.Fragment,null,r.a.createElement(E.a,{container:!0,justify:"center"},t.map((function(e){return r.a.createElement(E.a,{item:!0,key:e.name,className:a.authorAffiliationItem},r.a.createElement(h.a,{component:"h3",variant:"h6"},r.a.createElement(d.a,{href:e.url},e.name),r.a.createElement("sup",null,e.affiliation)))}))),r.a.createElement(E.a,{container:!0,justify:"center"},n.map((function(e){return r.a.createElement(E.a,{item:!0,key:e.name,className:a.authorAffiliationItem},r.a.createElement(h.a,{component:"h4",variant:"h6"},e.name,r.a.createElement("sup",null,e.number)))}))))}var B=t(317),_=Object(I.a)((function(e){return{bannerImg:{padding:e.spacing(2,0,6),backgroundColor:"transparent"}}}));function D(e){var a=_(),t=e.title,n=e.imageSrc,i=e.elevation;return r.a.createElement(b.a,{elevation:i,className:a.bannerImg},r.a.createElement(E.a,{alignItems:"center",justify:"center",container:!0},r.a.createElement(h.a,{component:"h3",variant:"subtitle1",color:"inherit",gutterBottom:!0},t),r.a.createElement(B.a,{component:"img",alt:t,src:n,title:t})))}var T=Object(I.a)((function(e){return{footer:{padding:e.spacing(6,0)}}}));function V(e){var a=T(),t=e.authorName,n=e.githubPage;return r.a.createElement("footer",{className:a.footer},r.a.createElement(p.a,{maxWidth:"lg"},r.a.createElement(h.a,{variant:"body2",color:"textSecondary",align:"center"},"Copyright \xa9 ",r.a.createElement(d.a,{color:"inherit",href:n},t)," ",(new Date).getFullYear(),".")))}var U=Object(I.a)((function(e){return{main:{textAlign:"center"},titleHead:{paddingTop:e.spacing(5),fontFamily:"Source Serif Pro","& > a > *":{margin:e.spacing(.5)}},bibtexSpan:{backgroundColor:e.palette.grey[200],marginTop:e.spacing(2),padding:e.spacing(1,4)},iconText:{wordWrap:"break-word"},img:{margin:"auto",display:"block",maxWidth:"100%",maxHeight:"100%"}}}));function J(){var e=U();return r.a.createElement("div",{className:e.main},r.a.createElement(P,{title:"Indoor Scene Layout Estimation from a Single Image",githubPage:"https://github.com/leVirve/lsun-room",sections:[{title:"Home",url:"#"},{title:"Abstract",url:"#abstract"},{title:"Paper",url:"#paper"},{title:"Download",url:"#download"}]}),r.a.createElement(p.a,{maxWidth:"lg"},r.a.createElement(M,null),r.a.createElement(Y,null),r.a.createElement(q,null),r.a.createElement(Z,null),r.a.createElement(X,null)),r.a.createElement(V,{authorName:"Hung-Jin Lin",githubPage:"https://github.com/levirve"}))}function M(){var e=U(),a="".concat("/lsun-room","/images/teaser.png");return r.a.createElement(r.a.Fragment,null,r.a.createElement(h.a,{component:"h1",variant:"h3",gutterBottom:!0,className:e.titleHead},"Indoor Scene Layout Estimation ",r.a.createElement("br",null),"from a Single Image ",r.a.createElement("br",null),[{text:"ICPR 2018",url:"https://iapr.org/archives/icpr2018/"},{text:"Room Layout",url:"https://iapr.org/archives/icpr2018/"}].map((function(e){return r.a.createElement(d.a,{key:e.text,href:e.url,target:"_blank",rel:"noopener"},r.a.createElement(f.a,{label:e.text}))}))),r.a.createElement(K,null),r.a.createElement(D,{elevation:0,imageSrc:a}))}function K(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(O,{authors:[{name:"Hung-Jin Lin",url:"https://tw.linkedin.com/in/hung-jin-lin-5b66119b",affiliation:"1"},{name:"Sheng-Wei Huang",url:"https://www.linkedin.com/in/sheng-wei-huang",affiliation:"1"},{name:"Shang-Hong Lai",url:"https://tw.linkedin.com/in/shang-hong-lai-4913a0b",affiliation:"1"},{name:"Chen-Kuo Chiang",url:"https://www.cs.ccu.edu.tw/~ckchiang",affiliation:"2"}],affiliations:[{number:"1",name:"National Tsing Hua University",url:""},{number:"2",name:"National Chung Cheng University",url:""}]}))}function Y(){var e=U();return r.a.createElement(r.a.Fragment,null,r.a.createElement(z,{anchor:"overview",name:"Overview"}),r.a.createElement(h.a,{component:"h3",variant:"h6",align:"left",paragraph:!0},"Unlike previous deep learning-based methods that depend on post-processing refinement (e.g., proposal ranking and optimization). We propose a deep learning-based approach for estimating the layout of a given indoor image in real-time. Our method consists of a fully convolutional network, a novel"," ",r.a.createElement("a",{href:"#method-layout-degrade"},"layout-degeneration")," augmentation method to mitigate the dataset imbalance, and a new training pipeline which integrate an adaptive edge penalty and smoothness terms into the training process without deploying postprocessing techniques."),r.a.createElement(z,{anchor:"method-layout-degrade",name:"Layout Degradation Augmentation",fontVariant:{variant:"h5"}}),r.a.createElement(E.a,{container:!0,justify:"center"},r.a.createElement(E.a,{item:!0},r.a.createElement("img",{src:"".concat("/lsun-room","/images/degrade_graph.png"),alt:"degrade_graph",className:e.img})),r.a.createElement(E.a,{item:!0},r.a.createElement("img",{src:"".concat("/lsun-room","/images/degrade_dataset.png"),alt:"degrade_graph",className:e.img}))),r.a.createElement(z,{anchor:"abstract",name:"Abstract"}),r.a.createElement(h.a,{component:"h3",variant:"h6",align:"left",paragraph:!0},"With the popularity of the hand devices and intelligent agents, many aimed to explore machine\u2019s potential in interacting with reality. Scene understanding, among the many facets of reality interaction, has gained much attention for its relevance in applications such as augmented reality (AR). Scene understanding can be partitioned into several subtasks (i.e., layout estimation, scene classification, saliency prediction, etc). In this paper, we propose a deep learning-based approach for estimating the layout of a given indoor image in real-time. Our method consists of a deep fully convolutional network, a novel layout-degeneration augmentation method, and a new training pipeline which integrate an adaptive edge penalty and smoothness terms into the training process. Unlike previous deep learning-based methods that depend on post-processing refinement (e.g., proposal ranking and optimization), our method motivates the generalization ability of the network and the smoothness of estimated layout edges without deploying postprocessing techniques. Moreover, the proposed approach is time-efficient since it only takes the model one forward pass to render accurate layouts. We evaluate our method on LSUN Room Layout and Hedau dataset and obtain estimation results comparable with the state-of-the-art methods."))}function Z(){var e=U(),a="".concat("/lsun-room","/images/thumb.jpg");return r.a.createElement(r.a.Fragment,null,r.a.createElement(z,{anchor:"paper",name:"Paper"}),r.a.createElement(f.a,{label:"IEEE Xplore",variant:"outlined",color:"primary"}),r.a.createElement(E.a,{item:!0},r.a.createElement(d.a,{href:"https://ieeexplore.ieee.org/document/8546278",target:"_blank",rel:"noopener"},r.a.createElement(D,{title:"Indoor Scene Layout Estimation from a Single Image, ICPR 2018 (IEEE Xplore)",elevation:0,imageSrc:a})),r.a.createElement(h.a,{align:"left",variant:"h6",color:"inherit",gutterBottom:!0},"Public PDF version is also provided in"," ",r.a.createElement("a",{href:"#download"},"downloadable section"),".")),r.a.createElement(z,{anchor:"citation",name:"Citation"}),r.a.createElement(h.a,{align:"left",variant:"h6",color:"inherit",gutterBottom:!0},'Hung-Jin Lin, Sheng-Wei Huang, Shang-Hong Lai, and Chen-Kuo Chiang, "Indoor Scene Layout Estimation from a Single Image", in Proceedings\n  of the International Conference on Pattern Recognition (ICPR), 2018'),r.a.createElement(f.a,{label:"BibTeX",variant:"outlined",color:"primary"}),r.a.createElement(b.a,{elevation:0,className:e.bibtexSpan},r.a.createElement(h.a,{align:"left",variant:"h6",color:"inherit",gutterBottom:!0},r.a.createElement("pre",{style:{wordWrap:"break-word",whiteSpace:"pre-wrap"}},"@inproceedings{lin2018layoutestimation,\n    Author = {Hung Jin Lin and Sheng-Wei Huang and Shang-Hong Lai and Chen-Kuo Chiang},\n    Title = {Indoor Scene Layout Estimation from a Single Image},\n    Booktitle = {2018 24th International Conference on Pattern Recognition (ICPR)},\n    Year = {2018}\n}"))))}function q(){var e=U(),a=[{name:"PDF",url:"https://github.com/leVirve/lsun-room/blob/master/doc/icpr2018_lin_layoutestimation.pdf",icon:y.a},{name:"Code",url:"https://github.com/levirve/lsun-room",icon:w.a},{name:"Video",url:"",icon:k.a},{name:"Demo Results",url:"",icon:S.a}];return r.a.createElement(r.a.Fragment,null,r.a.createElement(z,{anchor:"download",name:"Downloadable"}),r.a.createElement(E.a,{container:!0,justify:"center",spacing:1},a.map((function(a){return r.a.createElement(E.a,{item:!0,xs:2,key:a.url},r.a.createElement(d.a,{href:a.url,target:"_blank",rel:"noopener"},r.a.createElement(v.a,{component:a.icon,color:"action",style:{fontSize:50}}),r.a.createElement(h.a,{align:"center",variant:"h6",color:"inherit",className:e.iconText},a.name)))}))))}function X(){return r.a.createElement(r.a.Fragment,null,r.a.createElement(z,{anchor:"acknowledgments",name:"References"}),r.a.createElement(h.a,{variant:"body1",align:"left",paragraph:!0},"We thank"," ",r.a.createElement(d.a,{href:"http://lsun.cs.princeton.edu/2015.html#layout"},"LSUN Room 2016 Challenge,"," ")," ","and"," ",r.a.createElement(d.a,{href:"https://github.com/yuzhuoren/IndoorLayout"},"Yuzhuo Ren")," ","for providing datasets. ",r.a.createElement("br",null),[{title:"Recovering the spatial layout of cluttered rooms",link:"http://dhoiem.web.engr.illinois.edu/publications/iccv2009_hedau_indoor.pdf",suffix:"Varsha Hedau, Derek Hoiem, David Forsyth, ICCV 2009"},{title:"Learning Informative Edge Maps for Indoor Scene Layout Prediction",link:"https://slazebni.cs.illinois.edu/publications/iccv15_informative.pdf",suffix:"Arun Mallya, Svetlana Lazebnik, ICCV 2015"},{title:"A Coarse-to-Fine Indoor Layout Estimation (CFILE) Method",link:"https://arxiv.org/abs/1607.00598",suffix:"Yuzhuo Ren, Shangwen Li, Chen Chen, C.-C. Jay Kuo, ACCV 2016"},{title:"Learning to predict high quality edge maps for room layout estimation",link:"https://ieeexplore.ieee.org/document/7792744",suffix:"Weidong Zhang, Wei Zhang, Kan Liu, Jason Gu, IEEE Trans Multimedia 2017"},{title:"Delay: Robust spatial layout estimation for cluttered indoor scenes",link:"http://svl.stanford.edu/assets/papers/delay-robust-spatial.pdf",suffix:"Saumitro Dasgupta, Kuan Fang, Kevin Chen, Silvio Savarese, CVPR 2016"},{title:"Physics Inspired Optimization on Semantic Transfer Features: An Alternative Method for Room Layout Estimation",link:"https://sites.google.com/view/st-pio/",suffix:"Hao Zhao, Ming Lu, Anbang Yao, Yiwen Guo, Yurong Chen, Li Zhang, CVPR 2017"}].map((function(e,a){return r.a.createElement(r.a.Fragment,null,"[",a+1,"] ",r.a.createElement(d.a,{href:e.link},e.title),","," ",e.suffix,". ",r.a.createElement("br",null))}))))}var G=Object(s.a)({typography:{fontFamily:["Source Sans Pro","-apple-system","BlinkMacSystemFont",'"Segoe UI"',"Roboto",'"Helvetica Neue"',"Arial","sans-serif",'"Apple Color Emoji"','"Segoe UI Emoji"','"Segoe UI Symbol"'].join(",")},palette:{primary:{main:"#666"},secondary:{main:"#F092A0"}}});G.typography.h3=Object(l.a)({fontSize:"1.5rem",lineHeight:"1.167",fontWeight:400,fontFamily:G.typography.fontFamily},G.breakpoints.up("md"),{fontSize:"2.4rem"}),G.typography.h6=Object(l.a)({fontSize:"1rem",lineHeight:"1.6",fontWeight:500,fontFamily:G.typography.fontFamily},G.breakpoints.up("md"),{fontSize:"1.1rem"});var $=function(){return r.a.createElement(u.a,{theme:G},r.a.createElement("div",null,r.a.createElement(g.a,null),r.a.createElement(c.a,{basename:"/lsun-room"},r.a.createElement("div",null,r.a.createElement(m.a,{path:"/",exact:!0,component:J})))))};Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));o.a.render(r.a.createElement($,null),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()})).catch((function(e){console.error(e.message)}))}},[[160,1,2]]]);
//# sourceMappingURL=main.7e2f1038.chunk.js.map